{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8ea00-7ecc-4ea7-8fee-2fae207a5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import warnings\n",
    "import sklearn\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ast\n",
    "import os\n",
    "from scipy import stats\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad3572-5aff-4182-ad94-10357f1f7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_per_timepoint(df, min_points=5, plot=False, verbose=True):\n",
    "    \n",
    "    rows = []\n",
    "    total_patients = df['patient_id'].nunique()\n",
    "    \n",
    "    for pt, (pid, group) in enumerate(df.groupby('patient_id')):\n",
    "    \n",
    "        if verbose and pt % 1000 == 0:\n",
    "            print(f\"Processing patient {pt + 1} / {total_patients}\")\n",
    "        \n",
    "        group = group.sort_values('time_to_dg', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "        for i in range(len(group)):\n",
    "    \n",
    "            current = group.iloc[i]\n",
    "            past = group.iloc[:i+1] # Include also current datapoint\n",
    "            \n",
    "            row = {\n",
    "                'patient_id': pid,\n",
    "                'time_to_dg': current['time_to_dg'],\n",
    "                'disease_status' : current['disease_status'],\n",
    "                'risk_score_now': current['risk_score'],\n",
    "                'n_prev': len(past),\n",
    "            }\n",
    "    \n",
    "            current_time = current['time_to_dg']\n",
    "            time_1y_ago = current_time - 365\n",
    "            past_1y = past[(past['time_to_dg'] > time_1y_ago) & (past['time_to_dg'] <= current_time)]\n",
    "    \n",
    "            # If more than min points previous risk scores, get full history slope metrics\n",
    "            if len(past) >= min_points:\n",
    "                \n",
    "                times = past['time_to_dg'].values\n",
    "                scores = past['risk_score'].values\n",
    "                rel_times = times - times.max()\n",
    "            \n",
    "                # Fit a 1st-degree (linear) polynomial\n",
    "                coeffs = np.polyfit(times, scores, 1)\n",
    "                slope = coeffs[0]\n",
    "                intercept = coeffs[1]\n",
    "            \n",
    "                if plot == True:\n",
    "            \n",
    "                    # Create the fitted line\n",
    "                    fitted_scores = np.polyval(coeffs, times)\n",
    "                    plt.figure(figsize=(8, 5))\n",
    "                    plt.scatter(times, scores, color='blue', label='Data points')\n",
    "                    plt.plot(times, fitted_scores, color='red', label=f'Fitted line: y = {slope:.2f}x + {intercept:.2f}')\n",
    "                    plt.xlabel('times')\n",
    "                    plt.ylabel('scores')\n",
    "                    plt.title('Full history linear Fit')\n",
    "                    plt.legend()\n",
    "                    plt.grid(True)\n",
    "                    plt.show()\n",
    "            \n",
    "                row['mean_score'] = np.mean(scores)\n",
    "                row['max_score'] = np.max(scores)\n",
    "                row['slope'] = coeffs[0]\n",
    "                row['delta_score'] = scores[-1] - scores[0]\n",
    "                row['volatility'] = np.std(scores)\n",
    "                #row['auc'] = np.trapz(scores, x=rel_times)\n",
    "    \n",
    "                # If at least one risk scores measured during last year, get last 1 year slope metrics\n",
    "                if len(past_1y) > 1:\n",
    "                    times = past_1y['time_to_dg'].values\n",
    "                    scores = past_1y['risk_score'].values\n",
    "                    rel_times = times - times.max()\n",
    "                \n",
    "                    # Fit a 1st-degree (linear) polynomial\n",
    "                    coeffs = np.polyfit(times, scores, 1)\n",
    "                    slope = coeffs[0]\n",
    "                    intercept = coeffs[1]\n",
    "                \n",
    "                    if plot == True:\n",
    "                \n",
    "                        # Create the fitted line\n",
    "                        fitted_scores = np.polyval(coeffs, times)\n",
    "                        plt.figure(figsize=(8, 5))\n",
    "                        plt.scatter(times, scores, color='blue', label='Data points')\n",
    "                        plt.plot(times, fitted_scores, color='red', label=f'Fitted line: y = {slope:.2f}x + {intercept:.2f}')\n",
    "                        plt.xlabel('times')\n",
    "                        plt.ylabel('scores')\n",
    "                        plt.title('Past 1 year linear Fit')\n",
    "                        plt.legend()\n",
    "                        plt.grid(True)\n",
    "                        plt.show()\n",
    "                \n",
    "                    row['slope_1y'] = coeffs[0]\n",
    "                    row['delta_score_1y'] = scores[-1] - scores[0]\n",
    "                    row['volatility_1y'] = np.std(scores)\n",
    "                else:\n",
    "                    # If no data during last month, assume there is no change\n",
    "                    row['slope_1y'] = 0\n",
    "                    row['delta_score_1y'] = 0\n",
    "                    row['volatility_1y'] = 0\n",
    "        \n",
    "            rows.append(row)\n",
    "            \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba7e0a-1cd0-4840-a849-a7e6221a453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '~/mounts/research/husdatalake/disease/scripts/Preleukemia/oona_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0195be4a-4eb4-4e2f-b1ca-9b8f9f532bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = 'MF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c702757-4e44-4c70-a123-e2976f0d47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to include hard positives\n",
    "include_hp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd250e-e5ae-408b-9648-c557dc882bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many previous datapoints are needed for applying trajectory model\n",
    "min_points=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0378229-2356-4221-a165-5f78f73efbf9",
   "metadata": {},
   "source": [
    "# 1. Read deriv/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542e2bc-4e24-4403-8f01-f0a8611c6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_data = pd.read_csv(my_path + '/data/modelling/' + disease + '_derivation_data.csv', engine='c', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c86580-dd3b-49d7-b1dd-b92b05080e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(my_path + '/data/modelling/' + disease + '_test_data.csv', engine='c', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3712b-f112-4384-8687-9e6d2dcc8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_data = deriv_data[~deriv_data['henkilotunnus'].isin(test_data['henkilotunnus'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23780c0-88be-431f-9c40-2d3d41237d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSanity check: Is there any test data in derivation set')\n",
    "deriv_ht = list(deriv_data['henkilotunnus'].unique())\n",
    "test_ht = list(test_data['henkilotunnus'].unique())\n",
    "test_in_deriv = np.intersect1d(test_ht, deriv_ht).size > 0\n",
    "\n",
    "\n",
    "test_in_deriv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ee344-137d-4797-8f4d-27486eab31d0",
   "metadata": {},
   "source": [
    "## Read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e97e08-d2c6-4632-9e46-32eeb5923298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.Booster()  # Create a Booster object\n",
    "model.load_model(my_path + '/results/basic_model/' +  disease + '_basic_model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b83543-83da-4f84-93ae-ff0da8cd7c79",
   "metadata": {},
   "source": [
    "# 2. Extract features per timepoint using prior risk history for deriv data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc7f9a-aec8-4d35-81d4-04c2c5d2e069",
   "metadata": {},
   "source": [
    "### Predict risk scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8e669-116c-4683-90bc-37a69c5f4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_deriv = deriv_data.drop(columns=['henkilotunnus', 'disease', 'time_to_dg', 'hp'])\n",
    "y_deriv = deriv_data['time_to_dg']\n",
    "\n",
    "dderiv = xgb.DMatrix(x_deriv, label=y_deriv)\n",
    "\n",
    "deriv_risk_scores = model.predict(dderiv)\n",
    "\n",
    "deriv_info = deriv_data[['henkilotunnus', 'time_to_dg', 'disease', 'hp']]\n",
    "\n",
    "deriv_info['risk_score'] = deriv_risk_scores\n",
    "\n",
    "# Update 'time_to_dg' to negative if 'hp' == 0\n",
    "deriv_info['time_to_dg'] = np.where((deriv_info['disease'] == 1) & (deriv_info['hp'] == 0), -deriv_info['time_to_dg'], deriv_info['time_to_dg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e453d-1c08-453d-9f38-4ee6166cbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_patients = list(deriv_data[deriv_data['disease'] == 1]['henkilotunnus'].unique())\n",
    "healthy_patients = list(deriv_data[deriv_data['disease'] == 0]['henkilotunnus'].unique())\n",
    "patients = disease_patients + healthy_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7935068e-91aa-4d30-aa39-a3e7378c821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283277dd-688b-4e2d-9c38-cd9b5b54a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(disease_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4956d01-5fb3-410f-a409-53ccda7290af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter subset of healthy patients\n",
    "deriv_info = deriv_info[deriv_info['henkilotunnus'].isin(patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05462e1-e832-4235-8d45-6d9c366d63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = deriv_info.copy()\n",
    "\n",
    "if include_hp == True:\n",
    "    # Multiple hp datapoints measured on the same day -- linear fit does not converge\n",
    "    # Collapse data into single row\n",
    "    numeric_cols = df.select_dtypes(include='number').columns.difference(['time_to_dg'])  # Avoid aggregating grouping cols\n",
    "    df = df.groupby(['henkilotunnus', 'time_to_dg'], as_index=False)[numeric_cols].median()\n",
    "else:\n",
    "    ## Remove hp==1 rows\n",
    "    df = df[df['hp'] == 0]\n",
    "\n",
    "df = df.drop(columns=['hp'])\n",
    "\n",
    "df = df.rename(columns={'henkilotunnus': 'patient_id', 'disease': 'disease_status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcfdc7-f5c9-4010-86d5-553d0d980305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_df = extract_features_per_timepoint(df, min_points=min_points, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d4499-d471-46a8-a065-c2610d654053",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.head(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc36bfe-fc1a-4ae3-8801-94ed2d711744",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_hp == True:\n",
    "    features_df.to_csv('trajectory_model/' + disease + '_full_risk_score_deriv_data_with_hp.csv', index=False)\n",
    "else:\n",
    "    features_df.to_csv('trajectory_model/' + disease + '_full_risk_score_deriv_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a57fb-967a-4890-a33f-71bd7c9ae891",
   "metadata": {},
   "source": [
    "# 3. Extract features per timepoint using prior risk history for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd471e-fa0f-45cc-a642-8d2a053b1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_data.drop(columns=['henkilotunnus', 'disease', 'time_to_dg'])\n",
    "y_test = test_data['time_to_dg']\n",
    "\n",
    "dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "test_risk_scores = model.predict(dtest)\n",
    "\n",
    "test_info = test_data[['henkilotunnus', 'time_to_dg', 'disease']]\n",
    "\n",
    "test_info['risk_score'] = test_risk_scores\n",
    "\n",
    "# Update 'time_to_dg' to negative if disease\n",
    "test_info['time_to_dg'] = np.where((test_info['disease'] == 1), -test_info['time_to_dg'], test_info['time_to_dg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35393e97-7c97-43e8-b2c5-de24195d5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disease_patients = list(test_data[test_data['disease'] == 1]['henkilotunnus'].unique())\n",
    "test_healthy_patients = list(test_data[test_data['disease'] == 0]['henkilotunnus'].unique())\n",
    "test_patients = test_disease_patients + test_healthy_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436922b-8ee7-4581-9747-33c7516c69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_disease_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafd396-a9db-469e-bec4-af3278a5528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bcdf4-3fd7-4324-b6c8-9b0f70c86e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter subset of healthy patients\n",
    "test_info = test_info[test_info['henkilotunnus'].isin(test_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b3152-78a3-43b6-9b37-42c07b113714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_info.copy()\n",
    "\n",
    "df = df.rename(columns={'henkilotunnus': 'patient_id', 'disease': 'disease_status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ce0ad-4ee6-472e-9faa-880c9dfed59a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_features_df = extract_features_per_timepoint(df, min_points=min_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89352181-b465-4797-bf19-e3cac60045d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ae7b8-76e8-4826-8ab4-3c62485c245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_df.to_csv('trajectory_model/' + disease + '_risk_score_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e496e95-f087-468d-8d75-03b6e7c35442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
