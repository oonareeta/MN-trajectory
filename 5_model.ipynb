{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import warnings\n",
    "import sklearn\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sksurv.metrics import cumulative_dynamic_auc, concordance_index_censored\n",
    "import ast\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51338a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(deriv_data, shuffle=True, random_state=42):\n",
    "    # Divide patients to train / validation / groups\n",
    "    \n",
    "    random.seed(random_state)\n",
    "    # Divide patients to train / validation / groups\n",
    "    \n",
    "    patient_list = deriv_data['henkilotunnus'].unique()\n",
    "    \n",
    "    if shuffle == True:\n",
    "        random.shuffle(patient_list)\n",
    "    \n",
    "    # Calculate the number of items in each sublist\n",
    "    total_items = len(patient_list)\n",
    "    train_size = int(total_items * 0.85)\n",
    "    val_size = total_items - train_size  # To ensure all items are included\n",
    "\n",
    "    # Divide the list into sublists\n",
    "    train_list = patient_list[:train_size]\n",
    "    val_list = patient_list[train_size:]\n",
    "    \n",
    "    train_data = deriv_data[deriv_data['henkilotunnus'].isin(train_list)].reset_index(drop=True)\n",
    "    val_data = deriv_data[deriv_data['henkilotunnus'].isin(val_list)].reset_index(drop=True)\n",
    "\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadde161",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '~/mounts/research/husdatalake/disease/scripts/Preleukemia/oona_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabf1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = 'any_MN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb960083-9e40-4be8-8f80-c4a62ad0e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 100 # How many controls per patient to include training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ec0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_data = pd.read_csv(my_path + '/data/modelling/' + disease + '_derivation_data.csv', engine='c', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40fa610",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(my_path + '/data/modelling/' + disease + '_test_data.csv', engine='c', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a8943-993b-4bd2-aa1d-5e6489d4ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3610e85-164c-4cf8-b24b-5c52a848a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['feat'] = list(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353a5bb-dea8-492f-8681-1450c3323790",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('results/basic_model/'+ disease + '_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrounds = 1000\n",
    "early_stop = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2819708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSanity check: Is there any test data in derivation set')\n",
    "deriv_ht = list(deriv_data['henkilotunnus'].unique())\n",
    "test_ht = list(test_data['henkilotunnus'].unique())\n",
    "test_in_deriv = np.intersect1d(test_ht, deriv_ht).size > 0\n",
    "\n",
    "test_in_deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparams = pd.read_csv('optimization/hyperparams/' + disease + '_hyperparameter_results_cv.csv')\n",
    "max_idx = hyperparams['AUC_mean'].idxmax()\n",
    "params = ast.literal_eval(hyperparams['params'].loc[max_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c366f96-fb6f-4000-bef2-01d73e882a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae645d3-5274-4273-b3d7-8f996885c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_train_data(train_data, shuffle=True, random_state=42, ratio=100):\n",
    "    \n",
    "    ## Reduce number of healthy datapoints -- 100 healthy controls per patient\n",
    "    \n",
    "    train_disease = train_data[train_data['disease'] == 1]\n",
    "    train_healthy = train_data[train_data['disease'] == 0]\n",
    "    n_train_d = len(train_disease['henkilotunnus'].unique())\n",
    "    n_train_h = n_train_d * ratio\n",
    "    healthy_list = train_healthy['henkilotunnus'].unique()\n",
    "    \n",
    "    random.seed(random_state)\n",
    "    \n",
    "    if shuffle == True:\n",
    "        random.shuffle(healthy_list)\n",
    "    \n",
    "    healthy_subset = healthy_list[:n_train_h]\n",
    "    train_healthy_subset = train_healthy[train_healthy['henkilotunnus'].isin(healthy_subset)].reset_index(drop=True)\n",
    "    train_data = pd.concat([train_disease, train_healthy_subset], axis=0)\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37350cd",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_val_split(deriv_data, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f13212-d906-4523-918b-e2389af9c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <ratio> controls per 1 patient\n",
    "print('N train data rows before reduction: ', len(train_data))\n",
    "train_data = reduce_train_data(train_data, ratio=ratio)\n",
    "print('N train data rows after reduction: ', len(train_data))\n",
    "\n",
    "# Drop hard positive rows from validation data\n",
    "validation_data = validation_data[validation_data['hp'] != 1]\n",
    "\n",
    "## DELETE hp COLUMN FROM TRAIN / VAL\n",
    "train_data = train_data.drop(columns=['hp'])\n",
    "validation_data = validation_data.drop(columns=['hp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d5bf3-584a-4304-9e06-875e001d32cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del deriv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eae1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the class ratios\n",
    "pos_ratio_train = 100 * train_data['disease'].value_counts()[1] / train_data['disease'].value_counts()[0]\n",
    "pos_ratio_val = 100 * validation_data['disease'].value_counts()[1] / validation_data['disease'].value_counts()[0]\n",
    "pos_ratio_test = 100 * test_data['disease'].value_counts()[1] / test_data['disease'].value_counts()[0]\n",
    "print(f'\\n{pos_ratio_train} % of the datapoints in the training set had disease = 1')\n",
    "print(f'{pos_ratio_val} % of the datapoints in the validation set had disease = 1')\n",
    "print(f'{pos_ratio_test} % of the datapoints in the test set had disease = 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795149e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - is any of test indices in validation or training sets\n",
    "print('\\nSanity check: Is there any test data in train or validation sets')\n",
    "train_ht = list(train_data['henkilotunnus'].unique())\n",
    "validation_ht = list(validation_data['henkilotunnus'].unique())\n",
    "test_ht = list(test_data['henkilotunnus'].unique())\n",
    "test_in_val = np.intersect1d(test_ht, validation_ht).size > 0\n",
    "test_in_train = np.intersect1d(test_ht, train_ht).size > 0\n",
    "val_in_train = np.intersect1d(validation_ht, train_ht).size > 0\n",
    "print(test_in_val)\n",
    "print(test_in_train)\n",
    "print(val_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bff9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variables\n",
    "x_train = train_data.drop(columns=['henkilotunnus', 'disease', 'time_to_dg'])\n",
    "y_train = train_data['time_to_dg']\n",
    "\n",
    "x_val = validation_data.drop(columns=['henkilotunnus', 'disease', 'time_to_dg'])\n",
    "y_val = validation_data['time_to_dg']\n",
    "\n",
    "x_test = test_data.drop(columns=['henkilotunnus', 'disease', 'time_to_dg'])\n",
    "y_test = test_data['time_to_dg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844f54b-9fae-4c50-9d2c-df280655891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save x_train for getting SHAP values\n",
    "x_train.to_csv('results/basic_model/SHAP/' + disease + '_x_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6db74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dval = xgb.DMatrix(x_val, label=y_val)\n",
    "dtest = xgb.DMatrix(x_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use validation set to watch performance\n",
    "watchlist = [(dtrain,'train'), (dval,'eval')]\n",
    "\n",
    "# Store validation results\n",
    "evals_results = {}\n",
    "\n",
    "# Train the model\n",
    "print(f'\\nTraining the model with parameters: ')\n",
    "print(params)\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=nrounds, early_stopping_rounds=early_stop, evals=watchlist, evals_result=evals_results, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation losses\n",
    "tr_loss = list(evals_results['train'].values())[0]\n",
    "val_loss = list(evals_results['eval'].values())[0]\n",
    "plt.plot(range(len(tr_loss)), tr_loss, label='Training loss')\n",
    "plt.plot(range(len(tr_loss)), val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "xgb_model.save_model('results/basic_model/' + disease + '_basic_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict risk scores\n",
    "risk_scores_train = xgb_model.predict(dtrain)\n",
    "risk_scores_val = xgb_model.predict(dval)\n",
    "risk_scores_test = xgb_model.predict(dtest)\n",
    "\n",
    "# Add risk scores to the dataframe\n",
    "train_data['risk_score'] = risk_scores_train\n",
    "validation_data['risk_score'] = risk_scores_val\n",
    "test_data['risk_score'] = risk_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c8285-9a14-485d-9c8c-4e051ad29a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['risk_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a2e2b-ceb7-4f60-bf09-3fdcff59fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Separate the data\n",
    "censored = test_data[test_data['disease'] == 0]\n",
    "events = test_data[test_data['disease'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbc88c-49f4-4b8c-a40f-62dcbfbe1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "censored['risk_score'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da959a48-5ccf-43ef-b2f2-4eb5420c757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "censored['risk_score'].min() ,censored['risk_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0be6f4-3357-4ee4-9097-ea843edc0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "events['risk_score'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eb2633-49e6-4b40-88c8-208c10ff7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "events['risk_score'].min() ,events['risk_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064462c-e8db-4609-b0ab-44d6ee5b83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read binary threshold\n",
    "import json\n",
    "\n",
    "with open('results/basic_model/' + disease + '_threshold_youden.json', 'r') as f:\n",
    "    thresholds = json.load(f)\n",
    "\n",
    "binary_threshold = thresholds['med']\n",
    "\n",
    "print(binary_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cb23aa-9a40-4e11-89ae-b10efe7a5609",
   "metadata": {},
   "source": [
    "## Metrics on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative times to positive for getting c-index\n",
    "validation_data['time_to_dg'] = validation_data['time_to_dg'].apply(lambda x: -x if x < 0 else x)\n",
    "c_index = concordance_index_censored(event_indicator=validation_data['disease'].replace({0 : False, 1 : True}), event_time=validation_data['time_to_dg'], estimate=validation_data['risk_score'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate C-index for validation set\n",
    "#c_index = concordance_index(validation_data['time_to_dg'], -validation_data['risk_score'], validation_data['disease'])\n",
    "fpr, tpr, thresholds = roc_curve(validation_data['disease'], validation_data['risk_score'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Validation data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.box(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Convert risk scores to binary predictions using the optimal threshold\n",
    "predicted_labels = (validation_data['risk_score'] >= binary_threshold).astype(int)\n",
    "validation_data['predicted_disease'] = predicted_labels\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision, recall, pr_thresholds = precision_recall_curve(validation_data['disease'], validation_data['risk_score'])\n",
    "average_precision = average_precision_score(validation_data['disease'], validation_data['risk_score'])\n",
    "\n",
    "# Plot the PR curve\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.step(recall, precision, where='post', label=f'Average precision = {average_precision:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.box(False)\n",
    "plt.title(f'Validation data')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "cfm = sklearn.metrics.confusion_matrix(validation_data['disease'], validation_data['predicted_disease'])\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cfm.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in cfm.flatten()/np.sum(cfm)]\n",
    "labels = [f'{v1}\\n\\n{v2}' for v1, v2 in zip(group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cfm, annot=labels, annot_kws={'size': 18}, fmt='', cmap='Blues', cbar=False).set(ylabel='True label', xlabel='Predicted label')\n",
    "plt.title(f'Validation data')\n",
    "plt.show()\n",
    "\n",
    "TN = cfm[0][0]\n",
    "FN = cfm[1][0]\n",
    "TP = cfm[1][1]\n",
    "FP = cfm[0][1]\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "\n",
    "# Compute F1-score\n",
    "f1 = f1_score(validation_data['disease'], validation_data['predicted_disease'])\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(validation_data['disease'], validation_data['predicted_disease'])\n",
    "\n",
    "print(f\"F1-score for validation data: {f1}\")\n",
    "print(f\"Accuracy for validation data: {acc}\")\n",
    "print(f\"C-index for validation data: {c_index}\")\n",
    "print(f\"AUC for validation data: {roc_auc}\")\n",
    "print(f\"AUCPR for validation data: {average_precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a5914-f3ee-446f-b79a-598d2b6e349a",
   "metadata": {},
   "source": [
    "## Metrics on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88faea74-fd67-42d9-9e5c-e11c97f2c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res_path = 'results/basic_model/'\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative times to positive for getting c-index\n",
    "test_data['time_to_dg'] = test_data['time_to_dg'].apply(lambda x: -x if x < 0 else x)\n",
    "c_index = concordance_index_censored(event_indicator=test_data['disease'].replace({0 : False, 1 : True}), event_time=test_data['time_to_dg'], estimate=test_data['risk_score'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate C-index for test set\n",
    "#c_index = concordance_index(test_data['time_to_dg'], -test_data['risk_score'], test_data['disease'])\n",
    "fpr, tpr, thresholds = roc_curve(test_data['disease'], test_data['risk_score'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Test data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.box(False)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(res_path + disease + '_roc_auc_basic_model_test.png')\n",
    "\n",
    "\n",
    "# Convert risk scores to binary predictions using the optimal threshold\n",
    "predicted_labels = (test_data['risk_score'] >= binary_threshold).astype(int)\n",
    "test_data['predicted_disease'] = predicted_labels\n",
    "\n",
    "# Save with predictions\n",
    "test_data.to_csv(res_path + disease + '_test_data_with_predictions.csv')\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision, recall, pr_thresholds = precision_recall_curve(test_data['disease'], test_data['risk_score'])\n",
    "average_precision = average_precision_score(test_data['disease'], test_data['risk_score'])\n",
    "\n",
    "# Plot the PR curve\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.step(recall, precision, where='post', label=f'Average precision = {average_precision:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.box(False)\n",
    "plt.title(f'Test data')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(res_path + disease + '_pr_basic_model_test.png')\n",
    "\n",
    "cfm = sklearn.metrics.confusion_matrix(test_data['disease'], test_data['predicted_disease'])\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cfm.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in cfm.flatten()/np.sum(cfm)]\n",
    "labels = [f'{v1}\\n\\n{v2}' for v1, v2 in zip(group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cfm, annot=labels, annot_kws={'size': 18}, fmt='', cmap='Blues', cbar=False).set(ylabel='True label', xlabel='Predicted label')\n",
    "plt.title(f'Test data')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(res_path + disease + '_cfm_basic_model_test.png')\n",
    "\n",
    "TN = cfm[0][0]\n",
    "FN = cfm[1][0]\n",
    "TP = cfm[1][1]\n",
    "FP = cfm[0][1]\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "\n",
    "# Compute F1-score\n",
    "f1 = f1_score(test_data['disease'], test_data['predicted_disease'])\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(test_data['disease'], test_data['predicted_disease'])\n",
    "\n",
    "print(f\"F1-score for test data: {f1}\")\n",
    "print(f\"Accuracy for test data: {acc}\")\n",
    "print(f\"C-index for test data: {c_index}\")\n",
    "print(f\"AUC for test data: {roc_auc}\")\n",
    "print(f\"AUCPR for test data: {average_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae947a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c0b38-4fa6-4de2-89ad-0357670e5c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee086003-20f3-4b4a-8ef2-0c6818b3f9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcec6be-675e-48f5-bee6-817c2248162e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
